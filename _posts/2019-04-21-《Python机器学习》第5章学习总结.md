---
layout:     post
title:      "《Python 机器学习》第5章学习总结"
date:       2019-04-21
author:     "董国珍"
header-img: "img/post-bg-2015.jpg"
tags:
    - 数据分析
---




# 《Python 机器学习》第5章学习总结 
   

## 第五章 使用惩罚线性方法来构建预测模型

  

#### 运行算法进一步验证基扩展是否会提升预测性能

  
* 5.1 惩罚线性回归的 Python 包 
   
(Python包linear_model.ElasticNet用于在整个数据集上计算系数曲线，linear_model.ElasticNetCV通过交叉验证生成对ElasticNet模型性能的样本外估计。在一些情况下，为了更精细地控制交叉验证每一折验证使用的训练集和测试集，可能不能直接使用交叉验证的函数版本。 )
   
> 使用算法包优势：1.减少要编写以及调试的代码行数;2.另一个优势是包的运行速度快
>  
> cikit-learn算法包已经实现了套索、LARS 以及ElasticNet 回归  
>  
> 在一些情况下，为了更精细地控制交叉验证每一折验证使用的训练集和测试集，可能不能直接使用交叉验证的函数版本：
> >  
> >  1.如果问题包含一个类别属性，并且该类别属性的某个属性值出现较少，就需要通过抽样来确保每份数据中包含特定属性值的样本个数是等比例的。 
> >    
> >  2.也可能需要访问每折数据来计算错误统计量，比如不想使用CV包中的均方误差（MSE），想换用其他错误统计量，如平均绝对误差（MAE），因为它能更 好地代表实际问题中的错误
> >    
> >  3.另一种需要对每折数据计算错误的情况是使用线性回归来解决分类问题(分类问题使用的标准错误指标一般是误分类率或者ROC曲线下面积（AUC）)
> 注意：1.一些包（不是所有包）在模型拟合前会 自动对属性进行归一化；2.scikit-learn 包中变量的命名规则与之前略有不同。
  
    
* 5.2 多变量回归：预测红酒口感 
  
（回归问题，预测质量得分，可转化为分类问题）
  
在包含实数输出的问题上（回归问题）应用惩罚回归方法的过程
  
> 构建模型：1.通过样本外的性能来判断模型能否满足性能要求->2.部署前在整个数据集上进行训练(为了获得部署使用的最佳权重系数) ->3.基扩展：基于原始属性扩展新属性来改进性能 (为了进一步提高性能有可能需要对重要变量进行多次组合，进行多次尝试)
>
> 在整个数据集上进行训练是为了获得部署使用的最佳权重系数。交叉验证可以对模型性能进行评估，同时获得性能最好的α参数值
>
  
* 5.3 二分类：使用惩罚线性回归来检测未爆炸的水雷 
  
输出为二值情况下的惩罚线性回归方法
  
> 求解的步骤：
> >
> > （1）将二分类问题转换为回归问题。构建一个包含实数标签的向量，将其中一个类别 输出设为 0，另一个类别输出设为 1。 
> >   
> > （2）执行交叉验证。因为需要对每一份数据计算错误，交叉验证稍微复杂。Scikitlearn 包含一些便捷的功能来将这些计算流水化。 
>  
> 不使用 Python 中现成的交叉验证包:面向回归的交叉验证基于MSE。MSE对于回归问题是合理的，但对于分类问题则不是。 
>
> 混淆矩阵
>
* 5.4 多类别分类 - 分类犯罪现场的玻璃样本 
