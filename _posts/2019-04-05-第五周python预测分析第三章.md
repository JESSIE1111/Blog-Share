---
layout:     post
title:      "第五周python机器学习预测分析学习笔记"
date:       2019-04-05
author:     "桂志强"
header-img: "img/post-bg-2015.jpg"
tags:
    - python
    - 学习笔记
---


### 第三章：预测模型的构建：平衡性能，复杂性以及大数据

概括：讨论影响机器学习模型效果的因素，针对不同类型问题的性能定义



#### 3.1　基本问题：理解函数逼近

概括：特定的预测问题（包括两种变量）：

+ 尝试要预测的变量
+ 用来进行预测的变量

这类问题称作**函数逼近问题**。决定使用哪种属性进行预测被称作**特征工程**

特征工程一般需要通过一个由人工参与的、迭代的过程来完成特征选择，决定可能最 优的特征，并且尝试不同的特征组合。

**3.1.1　使用训练数据**

训练集包括 2 类数据： 

+ 要预测的结果 
+ 用于预测的特征 

预测因子（即特征、属性等）可以使用矩阵的形式来表示

预测目标也可能有多种数据类型:

+ 实数类型
+  2 分类问题

**3.1.2　评估预测模型的性能**

性能使用**均方误差**（MSE）或者**平均绝对误 差**（MAE）来度量

特别的是，**分类问题**需要使用不同的性能指标，最常用的性能指标是误分 类率，即计算 pred() 函数预测错误的样本比例

预测函数 pred()：需要评估其在新样本（未见过的）上的错误程度。



#### 3.2　影响算法选择及性能的因素——复杂度以及数据

概括：有几个因素影响预测算法的**整体性能**（包括问题的复杂度、模型复杂度以及 可用的训练数据量）

**3.2.1　简单问题和复杂问题的对比** 

对模型进行评估 的最佳经验是从训练数据集中预留部分数据。 

**样本外误差**：预留的数据包含类别标签，从而可以与模型生成的预测结果进行比对。

影响性能的一个因素是

+ **问题复杂度**
+ 另一个重要因素是**数据集的大小**。

**混合模型：**一组点，从多个浅色点以及深色点的分布中抽样

**问题复杂，拥有大量数据的复杂模型更精确，问题不复杂或者没有大量数据，线性模型更精确**



**3.2.2　一个简单模型与复杂模型的对比**

不考虑数据规模前提下：用复杂模型解决复杂问题，用简单模型解 决简单问题

**考虑数据规模**的话：在数据规模**较小**的前提下，两者性能基本一样



**3.2.3　影响预测算法性能的因素**

对于复杂问题进行精确预测需要大量数据

主要是数据矩阵的行列数



**3.2.4　选择一个算法：线性或者非线性** 

对于列比 行多的数据集或者相对简单的问题，倾向于使用线性模型

对于行比列多很多的复杂问 题，倾向于使用非线性模型

注意：线性方法要比非线性方法训 练时间短

一个非线性模型（如集成方法）对应于训练大量不同复杂度的模型



#### 3.3　度量预测模型性能

在回归问题中，真实目标以及预测值都是实 数，错误被定义为目标值与预测值的差异。

最常用的错误摘要是**均方误差（MSE）**以及**平均绝对错误（MAE）**。 MSE、MAE 以及根 MSE（也写作 RMSE，即 MSE 的平方根）

<!-- 各个计算方法省略，需要时自行查阅-->

注意：如果预测错误的MSE 同 目标方差几乎相等（或者 RMSE 与目标标准差几乎相等），此时，**过拟合**。

查看错误的分布直方图、长尾分布等对于分析错误原因以及错误程度也有用



分类问题：分类问题的评价方法一般围绕误分类率展开，即错分的样本 所占的比例。

（**混淆矩阵或列联表**）

**岩石 - 水雷数据集构建分类器过程**：

将数 据划分为 2 个子集：

+ **测试集**（包含 1/3 的数据）
+ **训练集**（包含剩下 2/3 的数据）

分类器训练：

+ 标签转换为 数值
+ 使用最小二乘法来拟合一个线性模型（使用scikit-learn 中的线性回归包）
+ 函数 confusionMatrix(预测值，对应实际标签，**决策阈值**) 生成**混淆矩阵**
+ 分别在训练集以及测试集上计算混淆矩阵

当决策阈值改变的话，误分类率也会改变。最佳决策阈值应该是能够最小化误分类率的值



使用其他的刻画错误方法：一种常见的指标被称作**接收者操作曲线**或者 **ROC 曲线**



**3.3.2　部署模型的性能模拟**

（模型训练的性能随着训练集规模的减小而下降）

预留数据集：

+ 测试数据集
+ n 折交叉验 证

**n 折交叉验 证**：

数据集被等分为n 份不相交的 子集，训练和测试需要多次遍历数据：

+ 第一次遍历：数据的第一块被预留 用于测试，剩下 n-1 块用于训练。
+ 第二次遍历：，第 2 块被预留做测试，剩下 n-1 块用于训练
+ 如此往复，直到所有数据都被预留一遍

n 折交叉验证可以估计预测错误：在多份样本上估计错误来估计错误边界

注意：测试样本应该能代表整个数据集。

模型经过训练和测试，还应该将训练集和测试集合并为一个更大的集合，重新 在该集合上训练模型



#### 3.4　模型与数据的均衡

概括：最小二乘法（OLS）的过拟合问题。

最小二乘法：是一个 有监督的学习算法，包括训练过程以及测试过程



**3.4.1　通过权衡问题复杂度、模型复杂度以及数据集规模来选择模型** 

前向逐步回归方法：

**最佳子集选择**

**3.4.2　使用前向逐步回归来控制过拟合** 

过程：

+ 在列的个数上增加一个约束（假设为 nCol）
+ 然后所有列中抽取特 定个数的列构成数据集，在上边执行最小二乘法
+ 遍历所有列的组合（列数为 nCol），
+ 找 到在测试集上取得最佳效果的 nCol 值
+ 增加 nCol 值，重复上述过程

以上过程产生最佳 的一列子集、两列子集一直到所有列子集。。对于每个子集同样有一个性能与之对应

最佳子集选择以及前向逐步回归过程基本类似，训练一系列的模型（列数为 1 训 练几个，列数为 2 训练几个，等等）。

这种方法产生了参数化的模型族（所有线性回归以 列数作为参数）。



**3.4.4　通过惩罚回归系数来控制过拟合——岭回归**

惩罚线性回归方法（简单版）：通过修改最小二乘法来控制模型复杂度从而避免过拟合

(最佳子集回归以及前向逐步回归通过限制使用的属性个数来控制回归的复杂度)

惩罚系数回归是使系数变小。一 种惩罚线性回归的方法被称作**岭回归**。（scikit-learn包给出了岭回归的实现）

与前向逐步回归不同的是：

岭回归通过不同的α值来控制模型数量，而不是通过属性个数来控制。

<!--岭回归示例：-->

<!--岩石 - 水雷数据集构建分类器-->

<!--代码省略，过程后补！！-->





**小结**:

围绕问题复杂性以及模型复杂性的可视化

讨论了针对不同问题（回归、分类以及多 分类）度量预测性能的多个评价指标

介绍了用于 在新数据上评估性能的 2 种方法